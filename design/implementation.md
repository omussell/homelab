% Bootstrapping a Secure Infrastructure
% Oliver Mussell
% 2016-2017

<!---

- Produced in Markdown with Vim, converted to HTML by Pandoc.
- Graphics created with DOT
- Hosted on Github Pages

-->

- [Overview](/homelab/design/overview.html)
- [Design](/homelab/design/design.html)
- [Implementation](/homelab/design/implementation.html)


Implementation
===

The architecture described in the design is only aimed at the infrastructure setup, not application servers. Each of the services provided can be accessed by other architectures based on different operating systems. So for example, Windows and Linux infrastructures would still be able to query the DNS service without any extra configuration.

It is also intended that the infrastructure is configured on bare-metal servers at the organisation site. The hardware requirements are scaled according to the organisation requirements. A small business in a single building could use a couple of old desktops; a medium business may use a half-rack of equipment in their headquarters; a large business may use a half-rack of equipment at each site.

The sizing requirements of each physical server (compute/storage) should prefereably be identical. This makes physical maintenance easier, and requires less hassle organising vendor hardware support. You can then provision VMs/Jails according to standard sizes based on Fibonacci numbers e.g. you have 16 CPU, 192GB RAM, this allows 12 - 1 CPU, 12GB RAM or 6 - 2 CPU, 24GB RAM or 3 - 4 CPU 48GB RAM and you can mix the sizes, but they will always be able to fit onto the hardware.

During the hardware provisioning, the SD card containing the standard NanoBSD image can be installed. This contains the bare-minimum configuration to allow the configuration management tools to continue the setup. On boot, the server contacts the control machine to download a new image and apply any updates if necessary.

The host (physical server running NanoBSD) can then complete its setup:

- Generate SSH keys
- Send SSH host public keys and SSHFP records to control machine
- SSH to control machine
- If a new image is available
	- Download updated image 
	- Reboot
- Install any required packages from local repo










SSH Bootstrapping Problem
---

## Problem Statement ###
As part of the provisioning process, the control machine and the new servers it creates must be able to communicate securely with one another, in order to exchange information and configuration data. This must be done without human intervention, so no passwords or interactive sessions. This must also be accomplished as part of the initial bootstrapping, where no other infrastructure yet exists (so no DNS, authentication etc.).

You do not have any advanced knowledge of the IP address or any other information autogenerated by the provisioned server. Since the IP address may be generated using SLAAC, we have no way of knowing what it is in advance. 

You may omit host key checking, and bypass the trust on first use (TOFU) paradigm. This can be done since configuration or secret data does not yet exist on the provisioned server. Also, we have some confidence of the servers identity since the connection between the server and control machine will be protected by IPsec (preconfigured, and a separate problem).

This can be accomplished with SSH, however, the authentication and trust setup of the initial connection and subsequent sessions requires some thought.

We want the control machine, and any other derivative machines to generate their keying material independently. Private keys / passwords should never be sent over the network. 

--- Attempting to find a solution ---

As part of the image build process, the public keys of the control machine are included in the image

- Host key in a hashed known_hosts file

	- # Find out the ip of the control machine, then use ssh-keyscan or ssh-keygen to generate the hashed host key.
	- ssh-keygen -F "control_machine_ip" -H | grep -v ^#	
	- # When using NanoBSD:
	- mkdir -p {NANO_WORLDDIR}/root/.ssh
	- output > {NANO_WORLDDIR}/root/.ssh/known_hosts

	- Alternative, pre-compute the host key (since a host key is just a normal private-public key pair, with no password. Also they can be shared and created on other machines.) and add the pre-computed host key to the image. The SSHFP record is generated and added to DNS by the control machine. Then when the control machine connects it can verify using DNS. The problem with this is that it only works if the DNS infrastructure is set up. How are the DNS servers set up in the first place? It also means that the private host key is included in the image build, which will be transmitted over the network to build the server, which is unacceptable.

	- There could be two processes: one for initial bootstrapping and a second once the basic infrastructure is created.


- User keys in an authorized_keys file

	- # The public key needs to go into either root's authorized_keys, or a new user.
	- Allowing login as root opens another security hole. PermitRootLogin needs to be set to yes in sshd_config. May not be that bad since it won't yet have any configuration data. 
	- Adding a new user is also difficult. How do you add a new user when the server is powered off, and you dont have any kind of shell access? You can modify files in the filesystem, but once mounted they are set to read only. This problem only affects the initial setup, because after the basic infrastructure is set up, LDAP can be used for user authentication. 

Once the server has been built and boots, it can generate its host and user keys.

The control machine then connects to the server using its public key to authenticate, and pulls the servers host and user public keys.

	- The server can rotate its host / user keys if they were pre-computed during the image build.

The control machine then adds the SSHFP records to DNS, and the user keys to LDAP 

This means that:

- private keys are not transmitted over the network.
- the control machine can connect securely to the server
- works in the absence of a SSH CA or DNS for validating via a third party


Alternative method, use a SSH CA on the control machine

Generate a SSH CA certificate on the control machine, and sign the hsot key of the control machine
Distribute the SSH CA cert onto the image

- ssh-keygen -A
- mkdir ~/ca
- cd ~/ca
- ssh-keygen -f ~/server_ca -t ed25519 -N ""
- ssh-keygen -s ~/server_ca -I CertAuth -h -n wintermute /etc/ssh/ssh_host_ed25519_key.pub
- 

after host keys are generated using ssh-keygen -A, they need to be saved onto the root filesystem to persist across reboots, otherwise they clear out

**or**

instead of doing all of the above, provision the new vm, then connect to it using ssh -o StrictHostKeyChecking=no, create an authorized_key file that contains the public key of the user that will be connecting from the control machine and add it to the image. Login as root on the provisioned vm, PermitRootLogin yes. Then change the config after that point.

The problem with this method is that you require advanced knowledge of the IP address of the server, and this isn't possible. We can't use DNS since it doesn't exist yet. The IP address may have been generated by SLAAC.

--- Possible Solution ---

CM=Control Machine

PM=Provisioned Machine

CM:

- Generate known_hosts file containing the host key of the CM
- Add new temp user account
- Generate SSH keys for the temp user account
- Generate an authorized_keys file with the public key of the temp user account (and the public key used by the configuration management tools if applicable)
- Add the known_hosts, authorized_keys, and private+public keys to the build image
- Build the image
- Provision the PM using the image

PM:

Connect to the CM using the private+public keys of the temp user account, and transfer the PM host keys and other information to the CM

CM:

Add PM host keys to CM known_hosts file
SSH to PM to apply configuration

Remove temp user account, and the private+public keys of the account

PM:

Remove private+public keys of the temp user account

---

Implementation commands:
(note that the following commands are quite verbose, and will be replaced with a much easier to read Ansible playbook in future)

CM:

Generate known_hosts file containing the host key of the CM

- Need to contruct the known_hosts key using the IP address of the CM followed by the host key
- First we need to find the interface, then use that to find the IP address
- ifconfig `ifconfig -l | awk '{print $1}'` | grep -w inet | cut -w -f3
- note that if IPv6 is used, change inet to inet6. Also may not work if the incorrect interface is chosen, or if there are multiple interfaces
- The host key also has a "root@$HOSTNAME" string at the end of the line, which needs to be removed in the known_hosts file
- So putting the commands together into a single line produces:


	ifconfig `ifconfig -l | awk '{print $1}'` | grep -w inet | cut -w -f3 > ~/cm_ip && cat /etc/ssh/ssh_host_ed25519_key.pub >> ~/cm_ip && cat ~/cm_ip | tr "\n" " " | sed 's/root.*//' > /usr/src/tools/tools/nanobsd/Files/etc/ssh/known_hosts && rm ~/cm_ip


Add new temp user account

	adduser -f tempuser.txt

- Where tempuser.txt contains:

	PM_HOSTNAME-tempuser:::::::/grim/$PM_HOSTNAME::

Generate SSH keys for the temp user account

	su -m $PM_HOSTNAME-tempuser -c 'mkdir -p ~/crypto/ssh'
	su -m $PM_HOSTNAME-tempuser -c 'ssh-keygen -f ~/crypto/ssh/id_ed25519 -t ed25519 -N "" -E sha256'

Generate an authorized_keys file with the public key of the temp user account (and the public key used by the configuration management tools if applicable)

	cp -v /grim/$PM_HOSTNAME/crypto/ssh/id_ed25519.pub /grim/$PM_HOSTNAME/crypto/ssh/authorized_keys
	cp -v /grim/$PM_HOSTNAME/crypto/ssh/authorized_keys /usr/src/tools/tools/nanobsd/Files/root/.ssh/authorized_keys


Add the known_hosts, authorized_keys, and private+public keys to the build image

	cp -v /grim/$PM_HOSTNAME/crypto/ssh/id_ed25519* /usr/src/tools/tools/nanobsd/Files/root/.ssh/

Build the image

	./nanobuild.sh

Provision the PM using the image

	./startnano.sh

PM:

Connect to the CM using the private+public keys of the temp user account, and transfer the PM host keys and other information to the CM

	scp /etc/ssh/ssh_host_ed25519_key.pub $PM_HOSTNAME-tempuser@$CM_IP:/grim/$PM_HOSTNAME/crypto/ssh

CM:

Add PM host keys to CM known_hosts file

	sed 's/^/$PM_IP /' /grim/$PM_HOSTNAME/crypto/ssh/ssh_host_ed25519_key.pub | sed 's/root.*//' >> ~/.ssh/known_hosts

SSH to PM to apply configuration

	The configuration management tool of choice uses SSH to connect to the PM and apply the configuration

Remove temp user account, and the private+public keys of the account

	rmuser -y $PM_HOSTNAME-tempuser
	
- Note that this command also removes the home directory of the temp-user

PM:

Remove private+public keys of the temp user account

	rm ~/.ssh/id_ed25519*

StrictHostKeyChecking vs VerifyHostKeyDNS Problem:
---

### Problem Statement ###

Do the StrictHostKeyChecking and VerifyHostKeyDNS options in ssh_config work together?

- StrictHostKeyChecking - If set to yes, ssh will never automatically add host keys to the known_hosts file and refuses to connect to hosts whose host key has changed(This is the preferred option). The host keys of known hosts will be verified automatically in all cases.
- VerifyHostKeyDNS - Specifies whether to verify the remote key using DNS and SSHFP resource records. If set to yes, the client implicitly trusts keys that match a secure fingerprint from DNS. Insecure fingerprints will be handled as if this option was set to ask. If this option is set to ask, information on fingerprint match will be displayed, but the user will still need to confirm new host keys according to the StrictHostKeyChecking option.

So if the fingerprint is presented from insecure DNS (not DNSSEC validated), or if the SSHFP record does not exist, does it prompt the user? We don't want this to happen since these SSH connections are happening autonomously.

Also need to check what happens if both options are set to yes.

If a host key is verified through DNS, is it still added to known_hosts? 


Setting up IPsec Problem:
---

### Problem Statement ###

How do we set up IPsec between the control machine and machines it creates?

How do we set up IPsec between the router and machines communicating with it?

How do we set up IPsec between the router and other sites?





Immutable NanoBSD Provisioning
---



How to perform updates to NanoBSD servers with Jails running?
---



Bootstrap
===


Version Control
---

Version control is used to track OS configuration files, OS and application binaries/source code and configuration management tool files. The version control tools and repositories should be shared by both infrastructure and applications files. 




Implementation
===



Provisioning
===

IPv6
---

### Address Autoconfiguration (SLAAC) ###

### SEND ###

### SEND SAVI ###

### DHCPv6 ###

### IPsec ###

### KINK ###

OS
---

### FreeBSD ###

### NanoBSD ###

### Jails ###

### ZFS ###

### Other Operating Systems/Containers/Filesystems ###

### Host Install Tools ###

### Ad-Hoc Change Tools ###

Configuration Management
===

DNS
---

### DNSSEC ###

### DANE ###

### DANE for Email Security ###

### DNSCrypt ###

### DNSCurve ###

LDAP
---

### LDAPS ###

### S/MIME or PGP ###

Kerberos
---


NTP
---

### NTPsec ###


App Deployment
===


NFS
---

### KerberizedNFSv4

Application Servers
---

### NGINX ###


Security and Compliance
===

Security and Crypto
---

### TLS ###

### SSH ###

### HSM ###
### Passwords ###
### TCP Wrapper ###
### IDS ###
### Firewalls ###

Configuration Management Tools
---

Authorisation / Access Control Lists
---

Role-Based Access Control / Shared Administration (sudo)
---

Domain Naming Service
---

Directory Service (LDAP)
---

Time Service
---

Logging / Auditing
---

RPC / Admin service
---

Orchestration
===

Specific Operational Requirements
---

### Configuration ### 

### Startup and shutdown ### 

### Queue draining ###

### Software upgrades ###

### Backups and restores ###

### Redundancy ###

### Replicated databases ###

### Hot swaps ###

### Access controls and rate limits ###

### Monitoring ###

### Auditing ###

Unspecific Operational Requirements
---

### Assigning IPv6 Addresses to Clients ### 

### Static or Dynamic IPv6 Addresses (DHCPv6 or SLAAC) ###

### IPv6 Security ###

### Hostname Conventions ###

### Choosing an Operating System ###

### Choosing a Configuration Management Tool ###

### Scheduling with cron ###

Scaling
===

User Access
===
